{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5debdaed",
   "metadata": {},
   "source": [
    "## Downloading historical prices for 1 min and 15 min by parallel API requests from alphavantage.co and generating aggregated data for each ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384343d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe27ea",
   "metadata": {},
   "source": [
    "### Generating a list of tickers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4b08b",
   "metadata": {},
   "source": [
    "First you need to find out which stocks have delisted over the past two years and exclude them from the list. New IPOs, on the contrary, is included in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b1e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delisted\n",
    "CSV_URL = 'https://www.alphavantage.co/query?function=LISTING_STATUS&date=2021-07-31&state=delisted&apikey=F9IT1SLG7FE0ZEW8'\n",
    "\n",
    "with requests.Session() as s:\n",
    "    download = s.get(CSV_URL)\n",
    "    decoded_content = download.content.decode('utf-8')\n",
    "    cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "    delisted_stocks_list = list(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8c0cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>ipoDate</th>\n",
       "      <th>delistingDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AACQU</td>\n",
       "      <td>Origin Materials Inc - Units (1 Ord Share Clas...</td>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>2021-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAN-W</td>\n",
       "      <td>Aarons Holdings Company Inc When Issued</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>2020-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACACU</td>\n",
       "      <td>PLAYSTUDIOS Inc - Units (1 Ord Share Class A &amp;...</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>2021-06-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACEL-WS</td>\n",
       "      <td></td>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>2020-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACND-U</td>\n",
       "      <td>Marketwise Inc - Units ( 1 Ord Cls A &amp; 0.5 Red...</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>2021-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>XBITV</td>\n",
       "      <td>XBiotech Inc</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>2020-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>XL-WS</td>\n",
       "      <td>XL Fleet Corp Wt Exp 06012025</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>XL-WS</td>\n",
       "      <td>XL Fleet Corporation - Warrants (01/06/2025)</td>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>2021-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>XPO-W</td>\n",
       "      <td>XPO Logistics Inc ExDistribution Whenissued</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2021-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>ZNOGW</td>\n",
       "      <td>Zion Oil &amp; Gas Inc - Warrants (31/01/2023)</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-11-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      symbol                                               name     ipoDate  \\\n",
       "0      AACQU  Origin Materials Inc - Units (1 Ord Share Clas...  2020-07-14   \n",
       "1      AAN-W            Aarons Holdings Company Inc When Issued  2020-11-25   \n",
       "2      ACACU  PLAYSTUDIOS Inc - Units (1 Ord Share Class A &...  2020-10-23   \n",
       "3    ACEL-WS                                                     2019-11-21   \n",
       "4     ACND-U  Marketwise Inc - Units ( 1 Ord Cls A & 0.5 Red...  2020-07-24   \n",
       "..       ...                                                ...         ...   \n",
       "344    XBITV                                       XBiotech Inc  2020-02-14   \n",
       "345    XL-WS                      XL Fleet Corp Wt Exp 06012025  2020-12-22   \n",
       "346    XL-WS       XL Fleet Corporation - Warrants (01/06/2025)  2019-09-03   \n",
       "347    XPO-W        XPO Logistics Inc ExDistribution Whenissued  2021-07-23   \n",
       "348    ZNOGW         Zion Oil & Gas Inc - Warrants (31/01/2023)  2020-09-02   \n",
       "\n",
       "    delistingDate  \n",
       "0      2021-06-24  \n",
       "1      2020-11-30  \n",
       "2      2021-06-21  \n",
       "3      2020-07-15  \n",
       "4      2021-07-21  \n",
       "..            ...  \n",
       "344    2020-02-19  \n",
       "345    2020-12-22  \n",
       "346    2021-02-26  \n",
       "347    2021-07-27  \n",
       "348    2020-11-05  \n",
       "\n",
       "[349 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stocks_delisted_list=[]\n",
    "for i in np.arange(1,len(delisted_stocks_list)):\n",
    "    delisting_date_string = datetime.fromisoformat(delisted_stocks_list[i][4])\n",
    "    date_limit = datetime.fromisoformat('2019-07-30')\n",
    "    if delisted_stocks_list[i][3]=='Stock' and delisting_date_string > date_limit:\n",
    "        my_stocks_delisted_list.append([delisted_stocks_list[i][0], delisted_stocks_list[i][1], delisted_stocks_list[i][4], delisted_stocks_list[i][5]])\n",
    "\n",
    "my_stocks_delisted_df = pd.DataFrame(my_stocks_delisted_list,columns=['symbol','name','ipoDate', 'delistingDate'])\n",
    "my_stocks_delisted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1db0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2019-08-01', '2021-07-29')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stocks_delisted_df.ipoDate.min(), my_stocks_delisted_df.ipoDate.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2336278e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AACQU', 'AAN-W', 'ACACU', 'ACEL-WS', 'ACND-U']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stocks_delisted_list_symbols = [delisted_stock[0] for delisted_stock in my_stocks_delisted_list]\n",
    "my_stocks_delisted_list_symbols[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2864317",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_stocks_delisted_list_symbols.txt\", \"w\") as fp:\n",
    "    json.dump(my_stocks_delisted_list_symbols, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911f5d2",
   "metadata": {},
   "source": [
    "As an index for working dates, we use the S&P500 ETF price dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951e6e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-10-19', '2021-10-18', '2021-10-15', '2021-10-14', '2021-10-13']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_SPY = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=SPY&outputsize=full&apikey=F9IT1SLG7FE0ZEW8'\n",
    "r_SPY = requests.get(url_SPY)\n",
    "data_SPY = r_SPY.json()\n",
    "list_SPY = list(data_SPY['Time Series (Daily)'].keys())\n",
    "dates = list_SPY[:list_SPY.index('2019-07-31')+1]\n",
    "dates[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88315dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stocks_list_per_date =[]\n",
    "for date in dates:\n",
    "    CSV_URL = 'https://www.alphavantage.co/query?function=LISTING_STATUS&date=' + date + '&state=active&apikey=F9IT1SLG7FE0ZEW8'\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(CSV_URL)\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        my_list = list(cr)\n",
    "        my_stocks_list=[]\n",
    "        for ticker in np.arange(1,len(my_list)):\n",
    "            if my_list[ticker][3]=='Stock' and my_list[ticker][0] not in my_stocks_delisted_list_symbols:\n",
    "                my_stocks_list.append(my_list[ticker])\n",
    "    my_stocks_list_per_date.append(my_stocks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tickers_list_total.txt\", \"w\") as fp:\n",
    "    json.dump(my_stocks_list_per_date, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d4597a",
   "metadata": {},
   "source": [
    "### Downloading from the generated list of tickers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc3ca26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8248"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"tickers_list_total.txt\", \"r\") as fp:\n",
    "    tickers_list_total = json.load(fp)\n",
    "len(tickers_list_total[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23088f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tickers = tickers_list_total[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29150d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = ['year1month1',\n",
    "'year1month2',\n",
    "'year1month3',\n",
    "'year1month4',\n",
    "'year1month5',\n",
    "'year1month6',\n",
    "'year1month7',\n",
    "'year1month8',\n",
    "'year1month9',\n",
    "'year1month10',\n",
    "'year1month11',\n",
    "'year1month12',\n",
    "'year2month1',\n",
    "'year2month2',\n",
    "'year2month3',\n",
    "'year2month4',\n",
    "'year2month5',\n",
    "'year2month6',\n",
    "'year2month7',\n",
    "'year2month8',\n",
    "'year2month9',\n",
    "'year2month10',\n",
    "'year2month11',\n",
    "'year2month12']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b387c6c",
   "metadata": {},
   "source": [
    "#### For 1 min historical data for the last two years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 150\n",
    "new_list = [all_tickers[i:i + n] for i in range(0, len(all_tickers), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers_list_total[0]:    \n",
    "    directory = ticker\n",
    "    parent_dir = 'C:/Users/Kuanysh/Downloads/pump_and_dump/all_tickers_1m'\n",
    "    path = os.path.join(parent_dir, directory) \n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c805b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_series(ticker, period):\n",
    "    CSV_URL = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol=' + ticker + '&interval=1min&slice=' + period + '&adjusted=false&apikey=F9IT1SLG7FE0ZEW8'\n",
    "    with requests.Session() as s:\n",
    "        retry = Retry(connect=3, backoff_factor=0.5)\n",
    "        adapter = HTTPAdapter(max_retries=retry)\n",
    "        s.mount('http://', adapter)\n",
    "        s.mount('https://', adapter)\n",
    "        download = s.get(CSV_URL)\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        ticker_quotes = list(cr)\n",
    "    \n",
    "    df = pd.DataFrame(ticker_quotes)\n",
    "    header_row=0\n",
    "    df.columns = df.iloc[header_row]\n",
    "    df = df.drop(header_row)\n",
    "    df.set_index('time', inplace=True)\n",
    "    \n",
    "    directory = ticker\n",
    "    parent_dir = 'C:/Users/Kuanysh/Downloads/pump_and_dump/all_tickers_1m'\n",
    "    path = os.path.join(parent_dir, directory) \n",
    "    df.to_csv(os.path.join(path, ticker  + '_' + period + '.csv'))\n",
    "    \n",
    "def get_tickers_paralell(tickers, period):\n",
    "    threads = list()\n",
    "    for ticker in tickers:\n",
    "        ticker_thread = threading.Thread(target=get_ticker_series, args=(ticker, period))\n",
    "        threads.append(ticker_thread)\n",
    "        ticker_thread.start()  \n",
    "    for tick_thread in threads:\n",
    "        tick_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec70489",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 7.7\n",
    "for p in tqdm(range(len(periods))):\n",
    "    for t in tqdm(range(len(new_list))):\n",
    "        start_time = time.perf_counter()\n",
    "        get_tickers_paralell(new_list[t], periods[p])\n",
    "        end_time = time.perf_counter()\n",
    "        execution_time = end_time - start_time\n",
    "        if execution_time < limit:\n",
    "            delay = limit - execution_time\n",
    "            print ('delay',delay)\n",
    "            time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(all_tickers))):\n",
    "    directory = all_tickers[i]\n",
    "    parent_dir = 'C:/Users/Kuanysh/Downloads/pump_and_dump/all_tickers_1m'\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    files = glob.glob(path + '/*')\n",
    "    df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.sort_values('time',ascending=False)\n",
    "    df = df.set_index('time', inplace=False)\n",
    "    next_dir = 'C:/Users/Kuanysh/Downloads/pump_and_dump/agg_tickers_1m'\n",
    "    df.to_csv(os.path.join(next_dir, all_tickers[i] + '.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2032a",
   "metadata": {},
   "source": [
    "#### For 15 min historical data for the last two years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204dfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 24\n",
    "new_list = [all_tickers[i:i + n] for i in range(0, len(all_tickers), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea55d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers_list_total[0]:    \n",
    "    directory = ticker\n",
    "    parent_dir = 'C:/Users/Kuanysh/Downloads/pump_and_dump/all_tickers_15m'\n",
    "    path = os.path.join(parent_dir, directory) \n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83756e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_series(ticker, period):\n",
    "    CSV_URL = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol=' + ticker + '&interval=15min&slice=' + period + '&adjusted=false&apikey=F9IT1SLG7FE0ZEW8'\n",
    "    with requests.Session() as s:\n",
    "        retry = Retry(connect=3, backoff_factor=0.5)\n",
    "        adapter = HTTPAdapter(max_retries=retry)\n",
    "        s.mount('http://', adapter)\n",
    "        s.mount('https://', adapter)\n",
    "        download = s.get(CSV_URL)\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        ticker_quotes = list(cr)\n",
    "    \n",
    "    df = pd.DataFrame(ticker_quotes)\n",
    "    header_row=0\n",
    "    df.columns = df.iloc[header_row]\n",
    "    df = df.drop(header_row)\n",
    "    df.set_index('time', inplace=True)\n",
    "    \n",
    "    directory = ticker\n",
    "    parent_dir = 'C:/Users/Kuanysh/Downloads/pump_and_dump/all_tickers_15m'\n",
    "    path = os.path.join(parent_dir, directory) \n",
    "    df.to_csv(os.path.join(path, ticker  + '_' + period + '.csv'))\n",
    "    \n",
    "def get_tickers_paralell(tickers, period):\n",
    "    threads = list()\n",
    "    for ticker in tickers:\n",
    "        ticker_thread = threading.Thread(target=get_ticker_series, args=(ticker, period))\n",
    "        threads.append(ticker_thread)\n",
    "        ticker_thread.start()  \n",
    "    for tick_thread in threads:\n",
    "        tick_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 6\n",
    "for p in tqdm(range(len(periods))):\n",
    "    for t in tqdm(range(len(new_list))):\n",
    "        start_time = time.perf_counter()\n",
    "        get_tickers_paralell(new_list[t], periods[p])\n",
    "        end_time = time.perf_counter()\n",
    "        execution_time = end_time - start_time\n",
    "        if execution_time < limit:\n",
    "            delay = limit - execution_time\n",
    "            print ('delay',delay)\n",
    "            time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a82fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(all_tickers))):\n",
    "    directory = all_tickers[i]\n",
    "    parent_dir = 'C:/Users/Kuanysh/Downloads/pump_and_dump/all_tickers_15m'\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    files = glob.glob(path + '/*')\n",
    "    df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.sort_values('time',ascending=False)\n",
    "    df = df.set_index('time', inplace=False)\n",
    "    next_dir = 'C:/Users/Kuanysh/Downloads/pump_and_dump/agg_tickers_15m'\n",
    "    df.to_csv(os.path.join(next_dir, all_tickers[i] + '.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
